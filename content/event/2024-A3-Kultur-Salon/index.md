---
title: "Mögliche Schädlichkeit von KI: Wie kann KI von Werten geleitet werden und wer trägt die Verantwortung?"

event: Kultursalon Schwaben 2024
event_url: 'https://a3kultur.de/nachrichten/kunstfreiheit-gedeckt'

location: 'Umweltbildungszentrum Augsburg (UBZ)'
# address:
#  street: Campus am Brunnenlech
# city: Pisa
# country: Italy
#  region: CA
#  postcode: '94305'

summary: Beitrag bei der Fokusnacht “Von der Kunstfreiheit gedeckt - Kunst, Meinungsfreiheit, Demokratie”"

abstract: "Large Language Models (LLMs oder Sprachmodelle) werden mit großen Mengen an Trainingsdaten trainiert, um plausible Sprachsequenzen zu erzeugen. Dadurch können sie in einer Vielzahl von KI-Technologien erfolgreich eingesetzt werden, wie z.B. Chatbots oder Schreibassistenten. Da die Trainingsdaten aus dem gesamten Web stammen (einschließlich Daten aus Büchern, Zeitungen, sozialen Medien und Diskussionsforen wie Reddit), besteht die Möglichkeit, dass ein LLM plausible Sequenzen erzeugt, die dennoch unerwünscht sind: z.B. rassistische und gewalttätige Ausdrücke oder Äußerungen, die mit Vorurteilen beladen sind.<br />
<br />
Würde sich eine Person so ausdrücken, hätten wir eine klare Vorstellung davon, was ihre Werte sind oder nicht sind. Wir selbst würden keine Aussagen machen, die nicht mit unseren Werten übereinstimmen. KI-Modelle wie LLMs hingegen, die mit Ausdrücken aus dem gesamten Web trainiert werden, spiegeln die Werte des gesamten Trainingsdatensatzes wider, was effektiv bedeutet, keine eigenen Werte zu haben. Sie werden darauf trainiert, plausible Sequenzen zu produzieren, aber nicht explizit darauf, Sequenzen zu erzeugen, die nicht schädlich sind.<br />
<br />
Die Versuche, eine KI auf bestimmte Werte auszurichten, werden als Alignment bezeichnet. Dabei werden die Verhaltensweisen einer KI mit denen von Menschen, die ein bestimmtes Wertesystem teilen, in Übereinstimmung gebracht. Alignment wird erreicht, indem menschliche Annotator*innen nach ihren Präferenzen befragt werden, die dann zur Optimierung der KI genutzt werden. Dadurch lernt die KI, im Einklang mit diesen Werten zu handeln, und entwickelt implizit eine Weltanschauung, die mit den menschlichen Präferenzen kohärent ist.<br />
<br />
Dies wirft die Frage auf, an wessen Werten sich die KI orientiert. Obwohl einige Unternehmen ihre Arbeit als »zum Wohle der Menschheit« motiviert darstellen, ist dies unwahrscheinlich. Stattdessen ist Alignment typischerweise kommerziell motiviert: Unternehmen sind für die KI-generierten Antworten ihrer Produkte (wie z.B. ChatGPT) verantwortlich und möchten durch Alignment Rufschädigungen vermeiden. Dennoch bringt KI-generierte Sprache Werte mit sich, und durch Alignment haben Unternehmen die Möglichkeit, diese zu beeinflussen. Beim Einsatz ihrer KI-Produkte in realen Anwendungen können sie somit auch die Gesellschaft beeinflussen. Die Frage, wessen Werte unsere KI-Produkte widerspiegeln, ist daher für unsere Gesellschaft relevant und sollte von jedem Nutzer von KI-Produkten kritisch hinterfragt werden."

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: "2024-09-27T19:00:00Z"
#date_end: "2022-05-25T20:00:00Z"
all_day: true

# Schedule page publish date (NOT talk date).
publishDate: "2017-01-01T00:00:00Z"

authors: []
tags: []

# Is this a featured talk? (true/false)
featured: false

image:
  caption: 'Image credit: [**a3kultur**](https://a3kultur.de/)'
#  focal_point: Right

#links:
#- icon: ""
#  icon_pack: fab
#  name: Dagstuhl report
#  url: "https://drops.dagstuhl.de/opus/volltexte/2014/4438/pdf/dagrep_v003_i011_p079_s13462.pdf"
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
# internal-project

# {{% callout note %}}
# Click on the **Slides** button above to view the built-in slides feature.
# {{% /callout %}}

# Slides can be added in a few ways:

# - **Create** slides using Wowchemy's [*Slides*](https://wowchemy.com/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
# - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
# - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

# Further event details, including [page elements](https://wowchemy.com/docs/writing-markdown-latex/) such as image galleries, can be added to the body of this page.

---
